{"cells": [{"cell_type": "markdown", "id": "f0b4f525", "metadata": {}, "source": ["# Evaluation dataset generation (Hugging Face sources)\n", "\n", "This notebook mirrors the logic in `generate_evaluation_dataset.py` to build the\n", "`evaluation_dataset_from_hf.csv` file with 100 prompts sampled from the specified\n", "Hugging Face datasets. Each run is reproducible via a fixed seed and produces the\n", "schema: `id, category, risk_level, prompt`."]}, {"cell_type": "code", "execution_count": null, "id": "48774bf0", "metadata": {}, "outputs": [], "source": ["from __future__ import annotations\n", "\n", "import pathlib\n", "from typing import Iterable, List, Optional, Tuple\n", "\n", "import pandas as pd\n", "from datasets import Dataset, DatasetDict, load_dataset\n", "\n", "SEED = 17\n", "OUTPUT_FILE = pathlib.Path(\"evaluation_dataset_from_hf.csv\")\n", "\n", "RISKY_LABELS = {\n", "    \"__possibly_needs_caution__\",\n", "    \"__probably_needs_caution__\",\n", "    \"__needs_caution__\",\n", "    \"__needs_intervention__\",\n", "}\n", "\n", "TARGET_COUNTS = {\n", "    \"child_qa_raw\": 25,\n", "    \"kidschatbot_raw\": 25,\n", "    \"cai_raw\": 25,\n", "    \"prosocial_raw\": 25,\n", "}"]}, {"cell_type": "code", "execution_count": null, "id": "4dc7b3bd", "metadata": {}, "outputs": [], "source": ["def clean_prompt(text: object) -> Optional[str]:\n", "    \"\"\"Normalize prompt text to a single-line string.\"\"\"\n", "    if text is None:\n", "        return None\n", "    prompt = str(text).strip().replace(\"\n", "\", \" \")\n", "    return prompt if prompt else None\n", "\n", "\n", "def collect_from_dataset(rows: List[dict], prompts: Iterable[str], category: str, limit: int) -> int:\n", "    \"\"\"Append up to ``limit`` prompts to ``rows`` with the standard schema.\"\"\"\n", "    added = 0\n", "    current_id = len(rows) + 1\n", "    for prompt in prompts:\n", "        if added >= limit:\n", "            break\n", "        cleaned = clean_prompt(prompt)\n", "        if not cleaned:\n", "            continue\n", "        rows.append(\n", "            {\n", "                \"id\": current_id,\n", "                \"category\": category,\n", "                \"risk_level\": \"unknown\",\n", "                \"prompt\": cleaned,\n", "            }\n", "        )\n", "        added += 1\n", "        current_id += 1\n", "    return added"]}, {"cell_type": "code", "execution_count": null, "id": "ac46ed5b", "metadata": {}, "outputs": [], "source": ["def sample_child_qa(limit: int) -> Tuple[str, List[str]]:\n", "    ds: Dataset = load_dataset(\"chaitanyareddy0702/Child-QA-dataset\", split=\"test\").shuffle(seed=SEED)\n", "    prompts = [row[\"Question\"] for row in ds]\n", "    return \"child_qa_raw\", prompts[:limit]\n", "\n", "\n", "def sample_kidschatbot(limit: int) -> Tuple[str, List[str]]:\n", "    dsdict: DatasetDict = load_dataset(\"yotev27367/KidsChatBot\")\n", "    split_name = next(iter(dsdict.keys()))\n", "    ds: Dataset = dsdict[split_name].shuffle(seed=SEED)\n", "    prompts = [row[\"Question\"] for row in ds]\n", "    return \"kidschatbot_raw\", prompts[:limit]\n", "\n", "\n", "def choose_cai_split(dsdict: DatasetDict) -> str:\n", "    preferred = [\n", "        \"test_sft\",\n", "        \"test_prefs\",\n", "        \"train_prefs\",\n", "        \"validation\",\n", "        \"test\",\n", "    ]\n", "    for name in preferred:\n", "        if name in dsdict:\n", "            return name\n", "    return \"train_sft\"\n", "\n", "\n", "def sample_cai(limit: int) -> Tuple[str, List[str]]:\n", "    dsdict: DatasetDict = load_dataset(\"HuggingFaceH4/cai-conversation-harmless\")\n", "    split_name = choose_cai_split(dsdict)\n", "    ds: Dataset = dsdict[split_name].shuffle(seed=SEED)\n", "    prompts: List[str] = []\n", "    for example in ds:\n", "        message = None\n", "        for msg in example.get(\"messages\", []):\n", "            if msg.get(\"role\") == \"user\":\n", "                message = msg.get(\"content\")\n", "                break\n", "        if message is not None:\n", "            prompts.append(message)\n", "        if len(prompts) >= limit:\n", "            break\n", "    return \"cai_raw\", prompts\n", "\n", "\n", "def sample_prosocial(limit: int) -> Tuple[str, List[str]]:\n", "    ds: Dataset = (\n", "        load_dataset(\"allenai/prosocial-dialog\", split=\"train\")\n", "        .filter(lambda ex: ex[\"safety_label\"] in RISKY_LABELS)\n", "        .shuffle(seed=SEED)\n", "    )\n", "    prompts = [row[\"context\"] for row in ds.select(range(min(limit, len(ds))))]\n", "    return \"prosocial_raw\", prompts"]}, {"cell_type": "code", "execution_count": null, "id": "949fe1e8", "metadata": {}, "outputs": [], "source": ["rows: List[dict] = []\n", "requested_total = sum(TARGET_COUNTS.values())\n", "\n", "samplers = [sample_child_qa, sample_kidschatbot, sample_cai, sample_prosocial]\n", "for sampler in samplers:\n", "    category, prompts = sampler(TARGET_COUNTS[sampler.__name__.replace(\"sample_\", \"\") + \"_raw\"])\n", "    collect_from_dataset(rows, prompts, category, TARGET_COUNTS[category])\n", "\n", "if len(rows) < requested_total:\n", "    deficits = requested_total - len(rows)\n", "    for sampler in samplers:\n", "        if deficits <= 0:\n", "            break\n", "        category, prompts = sampler(deficits)\n", "        deficits -= collect_from_dataset(rows, prompts, category, deficits)\n", "\n", "if len(rows) != 100:\n", "    raise ValueError(f\"Expected 100 prompts, found {len(rows)}\")\n", "\n", "df = pd.DataFrame(rows, columns=[\"id\", \"category\", \"risk_level\", \"prompt\"])\n", "\n", "expected_ids = list(range(1, len(df) + 1))\n", "if df[\"id\"].tolist() != expected_ids:\n", "    raise ValueError(\"IDs are not sequential starting at 1\")\n", "if df[\"prompt\"].isna().any() or (df[\"prompt\"].str.len() == 0).any():\n", "    raise ValueError(\"Empty prompts detected\")\n", "\n", "OUTPUT_FILE.write_text(df.to_csv(index=False))\n", "print(df[\"category\"].value_counts())\n", "df.head()"]}, {"cell_type": "code", "execution_count": null, "id": "3ff358ea", "metadata": {}, "outputs": [], "source": ["for category in TARGET_COUNTS:\n", "    subset = df[df[\"category\"] == category].head(2)\n", "    print(f\"\n", "Sample prompts from {category}:\")\n", "    for _, row in subset.iterrows():\n", "        print(f\"- {row['prompt']}\")"]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}